# Hand-Tear
If you also have trouble with hand-tearing code, We can provide you with some simple hand-tearing code cases, and hope it can help you! ðŸ‘»

### 1. ScaledDotProductAttention fuction [SDPA_I.py](https://github.com/cool-chicken/Hand-Tear-ML-Code/blob/main/SDPA_I.py)

- We abbreviate the fuction by calling it SDPA

$$ Attention(Q,K,V) = softmax( \frac{QK^{T}}{\sqrt{d_{k}}}) $$

### 2.MultiHeadAttention fuction []()
- We abbreviate the fuction by calling it MHA
- firstly, change the single head into multihead
- secondly, focus on output as a single head
- thirdly,the final output is obtained by affine transformation

### 3.
